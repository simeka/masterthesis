\chapter{Surrograte Gradient Descent on \acrshort{bss2}}

The second experiment in this thesis is done on the most recent tape-out of the \gls{bss2} platform the \gls{hx}. In contrast to the first experiment the neural coding scheme is changed from rate based to temporal based. The prerequisites for a temporal coding on \glspl{snn} is to find a suitable plasticity rule, that copes well with the non-differential nature of individual spikes. A possible candidate, SuperSpike, was presented in \cref{superspike}. With the access to the temporal evolution of the membrane potential, it is now possible to implement the learning rule for the \gls{bss2} platform.

% Ã¼berleitungssatz to the task
To challenge the surrogate gradient approach a constructed task that is equivalent to solving the XOR operator is taken from its original publication by \cite{zenke2018superspike}.

\section{Task}
A total of 96 input units, each firing once at a fixed random spike time, is split into four overlapping collections of different size. As in the exclusive-or, the four different input patterns are assigned to two target classes which are represented as two distinct neurons in the output layer. Despite the multiple input sources, the task is by construction only two-dimensional. The first input spike train $S_1$ overlaps with all other patterns. The units involved in $S_1$ can therefore be interpreted as bias units, since they will fire regardless of the active pattern. In analogy to the xor operator yielding $1 \veebar 0 = 0 \veebar 1 = 1$ for a single active input, the second and third spike train don't overlap except for the bias units. The union of $S_2$ and $S_3$ yields the final pattern, equaling to two active inputs $1 \veebar 1 = 0$. With respect to the xor operator, $S_1$ and $S_4$ yield class $0$ whereas the remaining two are part of class $1$. 

\begin{figure}
	\begin{subfigure}{0.5\textwidth}
		\caption{}
		\input{figures/superspiketasksector.pgf}
		\label{superspiketaskpicturesector}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\caption{}
		\input{figures/superspiketask.pgf}
		\label{superspiketaskpicture}
	\end{subfigure}
	\caption{(\subref{superspiketaskpicturesector}) A representative sector of the input data from the XOR-related task contains $2 + 4 + 4 + 6 = 16$ spikes from $2\times3$ different units and spike times. The first pattern ($S_1$) overlaps with all others and can be interpreted as a bias. The second and third pattern are disjoint apart from the  in the bias units and with the reference pattern, corresponding to $1 \veebar 0 = 0 \veebar 1 = 1$. The reference spike train is always on, equaling $1 \veebar 1 = 0$. (\subref{superspiketaskpicture}) The total number of input spikes per pattern is given by $20, 40, 40, 60$.
	\label{superspiketaskoverview}}
\end{figure} 

The fixed set of random times is picked from a $\SI{40}{\micro \s}$ time window, while the duration of a single measurement period is set to around $\SI{250}{\micro \s}$. In a slight modification to the derivation of SuperSpike, the error metric is changed from a single target spike $\hat{S}_i$ to a target time window $[\hat{t}_0, \hat{t}_1]$. Depending on the input pattern $p_j$, the error of the output unit $i$ corresponding to the target class $i$ is given by
\begin{equation}
e_i = \begin{cases}
\alpha \ast \left(e_\text{outside, i} + e_\text{inside, i}\right),& \quad \quad \text{if} \quad \text{class}(p_j) == i \\
- \alpha \ast S_i,& \quad \quad \text{else} 
\end{cases}
\end{equation}
In analogy to the von Rossum distance the error outside and inside the window can be written as 
\begin{align}
e_\text{outside}(t) &= - S_i(t) \cdot \left(H(\hat{t}_0 - t) + H(t - \hat{t}_1)\right) \\
e_\text{inside}(t) &= 
\begin{cases}
0 ,&\quad \quad \text{if} \quad \exists \; t^{(s)}_i \in [\hat{t}_0, \hat{t}_1], \\
\epsilon \ast \hat{t} ,& \quad \quad \text{else}.
\end{cases}
\end{align}
Despite the technical notation, the error follows the same principles as the von Rossum distance: If the target neuron spikes within the designated time span, zero error is returned. In case there occurs no spike inside the window, a target spike at time $\hat{t}$ will be added to the error instead. Any spikes outside the window sum with a negative sign. The error for the other output neuron is simple. Since it should remain silent, the error correlates to the negative spiking activity.

As in the previous experiment the accuracy is determined by the fraction of correctly identified inputs $n_\text{true}$ over the total number of inputs $n_\text{inputs}$
\begin{equation}
\text{Accuracy} = \frac{n_\text{true}}{n_\text{points}}.
\end{equation}
For debug reasons the accuracy was also monitored per pattern.

For the training, input batches of size eight are randomly drawn from a uniform distribution, resulting in an overall balanced training data set, but unbalanced batches. The performance of a test data set is evaluated on the fly by measuring the accuracy of all patterns after each parameter update. Depending on the initial conditions and the error propagation method (backpropagation or feedback alignment) the task converged after 500 to 2000 iterations.

\section{Implementation on the \acrshort{bss2} Platform}
The tape-out of the \gls{hx} came with some flaws requiring several software workarounds. To minimize the implementation effort the use of the chip is restricted to the upper half and only one \gls{ppu}. Unlike the previous experiment, SuperSpike is not implemented in an on-chip fashion. However, a key element of SuperSpike, the access to the membrane potential via the \gls{cadc} is implemented as an on-chip readout routine.

%The overall measurement period can be reduced to the length of several spike duration equivalents for temporal coded \glspl{snn}, making SuperSpike a candidate to process streaming spike data \emph{online}.
\subsection{\gls{cadc} Readout}
With a few \gls{ppu} instructions for the general purpose part and the vector unit, the readout of the \gls{cadc} is performed. The code base for the readout has been developed as a quick workaround by Aron Leibfried, since the software stack did not support the use of the vector unit at that time.

For the purpose of the experiment, the membrane traces are required to be sampled at high rate and to cover as much data as possible. The available memory on the \gls{ppu} limits the readout to 100 samples of 128 different neurons with a temporal resolution of roughly \SI{2.5}{\micro \s}. 

Before usable traces can be recorded with the \gls{cadc}, its characteristic needs to be calibrated. The \gls{cadc} has tunable an analog slope and offset parameter per quadrant. In addition to the per-quadrant settings, each channel has an individual offset parameter, that can be adjusted as well.

In the \cref{cadccalibration} the final state of the characteristics is plotted two quadrants from the chip half in use. The thereby implicated conversion from \gls{dac} lsb to \si{\V} will be used for most of the data shown throughout this chapter.
\begin{figure}
	\begin{subfigure}{0.5\textwidth}
		\caption{}
		\includegraphics[width=\textwidth]{figures/temporary/cadc_pre_calib_hx70.pdf}
		\label{precadccalib}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\caption{}
		\includegraphics[width=\textwidth]{figures/temporary/cadc_post_calib_hx70.pdf}
		\label{postcadccalib}
	\end{subfigure}
	\caption[Pre and post calibration state of the \gls{cadc}]{Pre and post calibration state of the \gls{cadc}. (\subref{precadccalib}) The raw cadc data of an controlled voltage ranging from 0 to \SI{1.2}{\V}. (\subref{postcadccalib}) the cadc parameters are manually adjusted, such that they cover a useful dynamic range. The offset per channel can then be easily computed and corrected. The manual method was preferred over an automated fit-routine, since the ramp and slope parameters showed a sensitive cross-dependency in certain areas.}
	\label{cadccalibration}
\end{figure}

\subsection{Calibration of \gls{lif} Neuron}
The new chip revision did not yet get rid of the imperfection the come with analog neuromorphic hardware. Despite the self-correcting behavior of learning algorithms, the chip requires at least some calibrating before the experiment can be executed.

At the time of the experiment, the development of chip-specific software for the new prototype was in an early stage. Among others, there was a lack of a calibration database and more generally, a lack of available calibrated hardware resources. This was largely due to an at that time slow and static calibration routine, that required the allocation of human and hardware resources for several hours to tune a setup.

The efficient parallelized readout of the \gls{cadc} presented itself to be a viable basis to put a quick alternative calibration routine into action. The main objective of the new routine is to provide a fast calibration that requires little interaction to bring a setup into a usable state with respect to the specific experiment requirements. 

Similar to the circles task, the binary search algorithm is chosen to find the proper \gls{dac} values of the analog parameters. Moreover, only a subset of the available parameters is tuned, namely the potentials of the \gls{lif} model \gls{v_leak}, \gls{v_reset} and \gls{thres}. By design, the potentials of the synaptic input $V_\text{syn, inh}$ and $V_\text{syn, exc}$ have a cross-dependency to the resting potential and thus need to be considered as well. The temporal constants \gls{tau_m} and \gls{tau_syn} are certainly important parameters in the \gls{lif} model, but the induced error by their misalignment is, at least for the chosen task, not heavily hampering the performance.

At the beginning, the calibration appeared to not work properly. A known issue is the cross talk between individual capacitive parameter memory cells, that arises if several cells are set to same value. By the design of the binary search algorithm, this event occurs repeatedly making the binary search a suboptimal choice for the calibration of the new chip. The development of a proper gradient based calibration has already been started, but for the use case in this experiment the existing code base could be sufficiently stabilized with two minor adaptations. First, a random variation is consequently applied to all ``unused" \gls{dac}-values and second, the binary search algorithm is extended with a fall back option of the best parameter setting so far. The results of the final calibration for the \gls{lif} parameters are shown in \cref{hxprepostcalib}.
\begin{figure}
	\begin{subfigure}{0.32\textwidth}
		\caption{}
		\centering
		\input{figures/vleak_pre_post_calibration.pgf}
		\label{hxprepostvleak}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
		\caption{}
		\centering
		\input{figures/vreset_pre_post_calibration.pgf}
		\label{hxprepostvreset}
	\end{subfigure}
	\begin{subfigure}{0.32\textwidth}
	\caption{}
	\centering
	\input{figures/vthreshold_pre_post_calibration.pgf}
	\label{hxprepostvthreshold}
\end{subfigure}
	\caption[Pre and post calibration state of the analog \gls{lif} parameters.]{Pre and post calibration state of the analog \gls{lif} parameters. (\subref{precadccalib}) The raw cadc data of an controlled voltage ranging from 0 to \SI{1.2}{\V}. (\subref{postcadccalib}) the cadc parameters are manually adjusted, such that they cover a useful dynamic range. The offset per channel can then be easily computed and corrected. The manual method was preferred over an automated fit-routine, since the ramp and slope parameters showed a sensitive cross-dependency in certain areas.}
	\label{hxprepostcalib}
\end{figure}




\subsection{Experimental Setup}
The experiment is mainly controlled by a Python class called \texttt{HXBlackbox} representing a minimalistic set of tools that puts the \gls{hx} into operation. The software has been co-written by Sebastian Billaudelle and Benjamin Cramer. These tools are in turn based on a new software stack for the \gls{bss2} platform, which is still under continuous development (\citealp{mueller2020bss2ll}).

The execution of the experiment is embedded in an existing Python-based simulation frame that is oriented on the implementation of SuperSpike in \citealp{zenke2018superspike}. The forward pass is then replaced by measuring the analog traces and spike times on the \gls{hx} before the respective updates of the network parameters are computed in the backward pass on the host. In the following a network with a single hidden layer containing 30 units, 96 input sources and two output neurons which serve as target classes is configured using the \texttt{HXBlackbox}.

\subsubsection{Chip based Forward Pass}
The implementation of the experiment using the  is straight forward. The setup of the multilayer network structure is implemented by the event router and the synapse array using corresponding weights and addresses to discriminate between input and recurrent connections. The issue that arises with alternating weights for a single synapse is solved by the same double-row approach from the previous experiment implementation (\cref{circlesimplementation}). However, in this case the workaround is already implemented within the \texttt{HXBlackbox} and the user only needs to properly fill a logical weight matrix that is divided into input and recurrent connections as shown in \cref{hxnetworksetup}.
\begin{figure}
\[
\sbox0{$\begin{matrix}1&2&3\\0&1&1\\0&0&1\\0&0&1\end{matrix}$}
\sbox1{$\begin{matrix}1&2&3\\0&1&1\\0&0&1\end{matrix}$}
\sbox2{$\begin{matrix}1&2\\0&1\end{matrix}$}
%
W_\text{logical}=\left(
\begin{array}{c c c}
\vphantom{\usebox{0}}\underbrace{\Bigg(\makebox[\wd0]{\large$I \rightarrow H$}\Bigg)}_{n_\text{h}}\Bigg\}\scriptstyle{n_\text{in}}&
\makebox[\wd0]{\Large0\quad} & 
\makebox[0.5\wd0]{\Large0}\\
%\hdashline[0.3pt/5pt]
\vphantom{\usebox{1}}	\makebox[\wd1]{\Large0\quad}&
\underbrace{\Big(\makebox[1.3\wd0]{\large$H \rightarrow O$}\Big)}_{n_\text{out}}\Big\}\scriptstyle{n_\text{h}} &
\makebox[0.5\wd1]{\Large0}\\

\vphantom{\usebox{2}}	\makebox[\wd2]{\Large0\quad}&
\makebox[\wd2]{\Large0\quad}&
\makebox[0.5\wd2]{\Large0}

\end{array}
\right)
=
\left(
\begin{array}{c c c}
\vphantom{\usebox{2}}\makebox[\wd2]{\Large$W^{(h)}$}&
\makebox[\wd2]{\Large0\quad} & 
\makebox[0.5\wd2]{\Large0}\\
%\hdashline[0.3pt/5pt]
\vphantom{\usebox{2}}	\makebox[\wd2]{\Large0\quad}&
\makebox[\wd2]{\Large$W^{(o)}$} &
\makebox[0.5\wd2]{\Large0}\\
\vphantom{\usebox{2}}	\makebox[\wd2]{\Large0\quad}&
\makebox[\wd2]{\Large0\quad} &
\makebox[0.5\wd2]{\Large0}

\end{array}
\right)
	\]
\caption[Structure of the logical weight matrix on \gls{hx}]{Structure of the logical weight matrix on \gls{hx}. The first $n_\text{in}$ rows are reserved for the inputs and connected to the $n_\text{h}$ hidden units ($I\rightarrow H$) and are set by the weight matrix $W^{(h)}$. The recurrent connections  $H\rightarrow O $ are managed the remaining rows ... Todo sort out where exactly (0,0) is...probably on the bottom left coroner}
\label{hxnetworksetup}
\end{figure}

The input pattern is formulated as an array containing tuples of the target neuron and a spike time. The forward pass is then evaluated by a designated \texttt{stimulate} function, which returns all recorded spikes at the end of the measurement. The membrane potential traces are measured by triggering the on-chip \gls{cadc} readout program on the \gls{ppu} as soon as the input pattern is injected by the host. 

\subsubsection*{Host based Backward Pass}
Within the simulation framework of SuperSpike the gathered experimental data of the membrane traces and the spike events is processed to determine the updates of the weight matrices as derived in \cref{superspike}. 

\begin{wrapfigure}{R}{0.45\textwidth}
	\centering
	\input{figures/cadcppuoffset.pgf}
	\caption[Offset measurement between \acrshort{cadc} traces and digital back end.]{Offset measurement between \acrshort{cadc} traces and digital back end. The time delta between peaks in the \acrshort{cadc} traces and the recorded spike times needs to be corrected.} 
	\label{cadcppuoffset}
\end{wrapfigure}

For a correct computations it is vital that both the measured \acrshort{cadc} traces and the recorded spike times by the digital back end are synchronized. In a respective offset measurement, the neurons are stimulated with a continuous input current such that they spike repetitively but with a low frequency. The located peaks in the resulting membrane traces are then compared to the digitally recorded spike times, yielding an offset $\Delta T$ of $(2.7 \pm 1.1)\; \si{\milli \s}$, see \cref{cadcppuoffset}. The recorded membrane maxes always before or exactly at the actual spike time, which results in a systematic error from evaluating the exact peak position in the \acrshort{cadc} traces. The offset has therefore been slightly corrected to $\Delta T_\text{corr} = (2.1 \pm 1.1)\; \si{\milli \s}$. 

In an attempt to optimize the performance of the Python based simulation environment, Python bindings are used to speed up time consuming code in C++. In the final setup, the runtime could be improved by about 25 percent. 

\subsubsection*{Initial Conditions and Hyperparameters}

The chosen initial conditions and hyperparameters for this experiment are inspired by the configuration in \citealp{zenke2018superspike}. However, some adaptations and a respective time-scaling had to be made, to cope with the accelerated analog hardware. ...
First temporal constants used in backward pass. \cref{temporalconstants}
\begin{table}\centering\ra{1.3}
	\begin{tabular}{@{}rlll@{}}\toprule
		& Parameter		& 	\gls{hx} & 	SuperSpike\footnote{\citealp{zenke2018superspike}} \\ \midrule
		& membrane constant \gls{tau_m}		& 	$\SI{8}{\micro \s}$ & 	$\SI{10}{\milli \s}$\\
		& synaptic constant \gls{tau_syn}	&	$\SI{5}{\micro \s}$ & 	$\SI{5}{\milli \s}$\\
		& $\alpha$ kernel constant $\tau_\alpha$	&	$\SI{12}{\micro \s}$& 	$\SI{10}{\milli \s}$\\
		& $\epsilon$ kernel constant $\tau_\epsilon$ 	&	$\SI{12}{\micro \s}$& 	$\SI{10}{\milli \s}$\\
		\bottomrule
	\end{tabular}
	\caption[Temporal hyperparameters for SuperSpike.]{Temporal hyperparameters for SuperSpike.}
	\label{temporalconstants}
\end{table}

And more lif neuron parameters

\begin{table}\centering\ra{1.3}
	\begin{tabular}{@{}rlll@{}}\toprule
		& Parameter								& 	hidden neurons 			& 	output neurons \\ \midrule
		& initial weights $w_{ij}^\text{init}$	& 	$\in \mathcal{N}(0,13)$ & 	$\in \mathcal{N}(0,18)$\\
		& resting potential \gls{v_leak}		&	$\SI{0.5}{\V}$ 			& 	$\SI{0.5}{\V}$\\
		& reset potential \gls{v_reset}			&	$\SI{0.4}{\V}$			& 	$\SI{0.4}{\V}$\\
		& threshold \gls{thres} 				&	$\SI{0.75}{\V}$			& 	$\SI{0.7}{\V}$\\
		& learning rate $\eta$ 					&	2000					& 	30			\\
		& slope of fast sigmoid $\beta_\sigma$ 	&	$\SI{0.05}{\V^{-1}}$		& 	$\SI{0.05}{\V^{-1}}$	\\
		\bottomrule
	\end{tabular}
	\caption[Initial and Hyperparameter per layer.]{Initial and Hyperparameter per layer.}
\end{table}

most important parameters in table from (hyperparams.npz)

threshold hidden/output
tau mem (not calibrated)
tau leak (not calibrated)
alpha 
eps
tau syn (theoretical! mention it somewhere)
%\begin{table}\centering\ra{1.3}
%	\begin{tabular}{@{}rcllclllcl@{}}\toprule
%		&layer	 & & $w_{ij}^\text{init}$		& \gls{v_leak} 	& \gls{v_reset}	& \gls{thres} 	& & $\eta$	\\ \midrule
%		&hidden  & & $\in \mathcal{N}(0,13)$	& $\SI{0.5}{\V}$& $\SI{0.4}{\V}$&$\SI{0.75}{\V}$& & 2000	\\
%		&output  & & $\in \mathcal{N}(0,18)$	& $\SI{0.5}{\V}$& $\SI{0.4}{\V}$&$\SI{0.7}{\V}$	& & 30		\\ \bottomrule
%	\end{tabular}
%	\caption[Hyperparameters for SuperSpike.]{Hyperparameters for SuperSpike. }
%\end{table}
%$\tau_sigma = \SI{0.05}{\V^{-1}}$






learning rates

no need for bias, bias is part of the task

no need for noise, there is plenty of noise there (check the traces from the figures)

\section{Training and Results}

The performance of the SuperSpike approach is now tested using different propagation methods in the backward pass. All experiments have been 



The training data set of the classifcation task consists of a total of 2000 minibatches of size eight. The minibatches are created by randomly drawing eight patterns from a uniform distribution, yielding an overall balanced data set. The validation data simply contains every pattern a single time.

Minibatch of size 8

2000 iterations and seeds = trials = 10

testing with each pattern (4)

accuracy

Different methods: BP, FA (uniform vs normal), no hidden learning, no hidden layer

Different setups? (63 vs 73)


\begin{figure}
	\centering
	\input{figures/superspiketaskconsecutive.pgf}
	\caption[Example of a training batch.]{Example of a training batch. After The chosen batch-size for the XOR-related task is eight. The network evaluates}
	\label{inputofabatch}
\end{figure}


\begin{figure}
	\centering
	\input{figures/debug_plot_0_100.pgf}
	\caption[Monitoring of the analog traces measured on the \gls{hx}.]{Monitoring of the analog traces measured on the \gls{hx}. Each column represents an important observable for the backward pass. The hidden and output layer are discriminated row-wise. The first column, contains the information of the presynaptic spike train spike train $S_j^{(l)}$, the second column shows the evolution of the membrane potential \gls{v_mem} with respect to the total synaptic input generated by the incoming spikes and in the third column the adapted von Rossum error $e^{(l)}$ is displayed.}
	\label{debugplot}
\end{figure}

...
\begin{figure}
	\centering
	\input{figures/dweight_plot_0_100.pgf}
	\caption[Traces in the backward pass using SuperSpike.]{Computation traces of the backward pass using SuperSpike. The integrand of the weight update $\Delta w_{ij}^{(o)}$ is given by the adapted von Rossum error $e^{(o)}$ (first column) and the convolution of the surrogate gradient with the presynaptic spike activity $\lambda_{ij}^{(o)} = \alpha \ast \left(\sigma'(V_{\text{m},i}^{(o)}) \left(\epsilon \ast S_j^{(o)}\right)\right)$ (second column). The final weight update is given by the sum over temporal traces of the last column.}
	\label{weightchangesplot}
\end{figure}


\begin{itemize}
	\item Backprop weights, FA, no hidden layer learning
\end{itemize}