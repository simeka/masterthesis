\chapter{Background}
Starting my final year project at the Electronic Vision(s) group, I soon realized the diversity of their research. From the biological view of the human brain to electronic circuit laws further to machine learning algorithms, the required knowledge to work in this field is broad and manifold. In the next paragraphs, I will introduce the most important concepts and physical backgrounds upon which the presented research in this works is based on.

\section{The Biological Neuron}

Describe: Soma, Axon, Synapse, Neuron, Membrane, ... but read the to be cited literature on it first so that not too much none sense comes up.

Hodgkin Hoxley Model


\subsection{Neuromorphic Hardware}
Cuda/Coda


\section{Deep Learning}

The last decade was filled with inventions and technologies of machine learning nature. Among the many tools machine learning has provided to the scientific community, deep learning is one where many still struggle to grasp its mechanism and capabilities. However, it has become a useful and powerful tool to solve complex tasks and furhtermore lead to spead up the progress in various fields of research - one in particular: artificial intelligence.

ToDo: Literatur Book zu Deep Learning (siehe downloads UniRechner)

Ãœberleitung zu rate coding vs sparse coding (maybe read again SuperSpike17/19 first))
A spiking neural network (SNN) offers many advantages compared to a classical artifical neural network (ANN). On of the major differences is that sparse coding allows the user to compress a lot of information into a single spike. Also not spiking at a sppecifencodes information.  This efficient way of transporting information makes SNNs a contender for any energy sensitive form of computing. More importantly it also opens up the doors to understanding spike-based computing better and thus also the way the human brain works.